<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
      <title>Posts on still deeper </title>
      <generator uri="https://gohugo.io">Hugo</generator>
    <link>http://chopl.in/post/</link>
    <language>ja-JP</language>
    
    
    <updated>Tue, 09 Sep 2014 00:00:00 UTC</updated>
    
    <item>
      <title>D進します</title>
      <link>http://chopl.in/post/2014/09/09/go_to_doctoral_course/</link>
      <pubDate>Tue, 09 Sep 2014 00:00:00 UTC</pubDate>
      
      <guid>http://chopl.in/post/2014/09/09/go_to_doctoral_course/</guid>
      <description>

&lt;h2 id=&#34;tl-dr:2cb0e3542ec977f92c11ebd54376c7b6&#34;&gt;tl;dr&lt;/h2&gt;

&lt;p&gt;2014年10月から東京大学大学院 情報理工学研究科 電子情報学専攻 博士後期課程に進学します。&lt;/p&gt;

&lt;h2 id=&#34;今後の予定:2cb0e3542ec977f92c11ebd54376c7b6&#34;&gt;今後の予定&lt;/h2&gt;

&lt;p&gt;軸足は博士課程に置きますが、当面のところは現職は稼働を減らして続けることになっています。&lt;/p&gt;

&lt;h2 id=&#34;求人:2cb0e3542ec977f92c11ebd54376c7b6&#34;&gt;求人&lt;/h2&gt;

&lt;p&gt;現職で元々人手不足感があったところに、私の手も減ってしまうので絶賛求人中です。&lt;/p&gt;

&lt;p&gt;今どきのキラキラしたオフィスなどはないですが、今回の進学のような個人の都合もちゃんと話を聞いてもらえるので、大変働きやすい職場だと思っています。&lt;/p&gt;

&lt;p&gt;wantedlyから応募して頂いても私に直接声をかけて頂いても構いません。興味のある方は是非話をしにきて下さい。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.wantedly.com/companies/scaleoutinc&#34;&gt;スケールアウトの最新情報 - Wantedly&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>入門Ansibleをレビューしました</title>
      <link>http://chopl.in/post/2014/08/01/review_of_ansible_introduction/</link>
      <pubDate>Fri, 01 Aug 2014 00:00:00 UTC</pubDate>
      
      <guid>http://chopl.in/post/2014/08/01/review_of_ansible_introduction/</guid>
      <description>

&lt;h2 id=&#34;入門ansibleについて:aaaeeb7131c14ff4737c1a7513adf130&#34;&gt;入門Ansibleについて&lt;/h2&gt;

&lt;p&gt;縁があってレビューさせて頂いたので、所感をまとめておきます。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; lang=&#34;ja&#34;&gt;&lt;a href=&#34;https://twitter.com/choplin/statuses/495038435560652800&#34;&gt;&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; lang=&#34;ja&#34;&gt;&lt;a href=&#34;https://twitter.com/choplin/statuses/495038639970074624&#34;&gt;&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; lang=&#34;ja&#34;&gt;&lt;a href=&#34;https://twitter.com/choplin/statuses/495038945529298945&#34;&gt;&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; lang=&#34;ja&#34;&gt;&lt;a href=&#34;https://twitter.com/choplin/statuses/495039580316237824&#34;&gt;&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/p&gt;

&lt;h2 id=&#34;ansibleについて:aaaeeb7131c14ff4737c1a7513adf130&#34;&gt;Ansibleについて&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;半年くらい業務でも使っている

&lt;ul&gt;
&lt;li&gt;chefと併用中&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;大人の意見であれば、ツールは目的に合わせて使い分けるべきだが、個人的にはchefより使いやすいと考えている

&lt;ul&gt;
&lt;li&gt;ざっくりとした理由としては、ansibleの方が

&lt;ul&gt;
&lt;li&gt;小さく始めやすい&lt;/li&gt;
&lt;li&gt;他のツールと組み合わせやすい&lt;/li&gt;
&lt;li&gt;アドホックな操作をやりやすい&lt;/li&gt;
&lt;li&gt;凝ったことはできないので、見通しがいい&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;chefはサーバー管理の大半をchef-wayでやれるなら利点が大きいと思います&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>fluent-plugin-event-snifferというプラグインを書いた</title>
      <link>http://chopl.in/post/2014/07/28/fluent_plugin_event_sniffer/</link>
      <pubDate>Mon, 28 Jul 2014 00:00:00 UTC</pubDate>
      
      <guid>http://chopl.in/post/2014/07/28/fluent_plugin_event_sniffer/</guid>
      <description>

&lt;h2 id=&#34;tl-dr:b2b897118f0912808e2b20ed2c65452a&#34;&gt;tl;dr;&lt;/h2&gt;

&lt;p&gt;fluetndに流れているイベントをWeb UI上で確認できる fluent-plugin-event-sniffer というプラグインを書いた。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/choplin/fluent-plugin-event-sniffer&#34;&gt;https://github.com/choplin/fluent-plugin-event-sniffer&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;概要:b2b897118f0912808e2b20ed2c65452a&#34;&gt;概要&lt;/h2&gt;

&lt;p&gt;以前、コマンドラインからfluentdのイベントを見ることができる、 &lt;a href=&#34;http://chopl.in/blog/2014/03/06/introduction_of_fluent_tail.html&#34;&gt;fluent-tailというツールを書いた&lt;/a&gt; んですが、Webアプリ版が欲しいという声がチラホラあったので作りました。&lt;/p&gt;

&lt;h2 id=&#34;デモ:b2b897118f0912808e2b20ed2c65452a&#34;&gt;デモ&lt;/h2&gt;

&lt;iframe width=&#34;480&#34; height=&#34;320&#34; src=&#34;//www.youtube.com/embed/_ykzeP2xGNg?rel=0&#34; frameborder=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;
</description>
    </item>
    
    <item>
      <title>RHEL6系でansibleを使うならrecord_host_keysをFalseにすると速くなる</title>
      <link>http://chopl.in/post/2014/07/26/set_record_host_keys_to_false/</link>
      <pubDate>Sat, 26 Jul 2014 00:00:00 UTC</pubDate>
      
      <guid>http://chopl.in/post/2014/07/26/set_record_host_keys_to_false/</guid>
      <description>

&lt;p&gt;tl;dr;&lt;/p&gt;

&lt;p&gt;タイトルの通り。RHEL6系なのでCentOS6、ScientificLinux6なども該当。&lt;/p&gt;

&lt;h2 id=&#34;pramiko:40eebbc67ccce246446fd64a1b7ebc69&#34;&gt;Pramiko&lt;/h2&gt;

&lt;p&gt;ansibleは各ホストとの接続にはsshと使います。この時、sshにはControlPersistという機能に対応していることが必要で、opensshならバージョン5.6以上が対象です。ansibleのデフォルトの動作では、PATH上のsshコマンドがControlPersistに対応していればsshを使い、そうでない場合はparamikoというpythonのsshライブラリが用いられるようになっています。&lt;/p&gt;

&lt;p&gt;RHEL6系のopensshはバージョン5.3の為、何も設定せずに使うとparamikoが用いられます。&lt;/p&gt;

&lt;h2 id=&#34;paramikoが遅い:40eebbc67ccce246446fd64a1b7ebc69&#34;&gt;Paramikoが遅い&lt;/h2&gt;

&lt;p&gt;ところがこのparamikoを用いたansibleの実行はかなり遅いです。どの程度遅いかは末尾を参照。特に台数が多い場合にその影響が目立ち、forkを増やして実行してもあまり速く感じないです。&lt;/p&gt;

&lt;p&gt;ansibleコマンドを実行した時に、どこが遅いかコードを辿って行くと&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ansible/ansible/blob/4a8e0688555e7dcccb84732962d00af0b8274431/bin/ansible#L186&#34;&gt;Runner#run&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ansible/ansible/blob/4a8e0688555e7dcccb84732962d00af0b8274431/lib/ansible/runner/__init__.py#L1268&#34;&gt;_parallel_exec&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ansible/ansible/blob/4a8e0688555e7dcccb84732962d00af0b8274431/lib/ansible/runner/__init__.py#L78&#34;&gt;_executor&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ansible/ansible/blob/4a8e0688555e7dcccb84732962d00af0b8274431/lib/ansible/runner/__init__.py#L558&#34;&gt;_executor_internal&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ansible/ansible/blob/4a8e0688555e7dcccb84732962d00af0b8274431/lib/ansible/runner/__init__.py#L687&#34;&gt;_executor_internal_inner&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ansible/ansible/blob/4a8e0688555e7dcccb84732962d00af0b8274431/lib/ansible/runner/__init__.py#L910&#34;&gt;Connection#close&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ansible/ansible/blob/4a8e0688555e7dcccb84732962d00af0b8274431/lib/ansible/runner/connection_plugins/paramiko_ssh.py#L337&#34;&gt;hostkeyの追加処理&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;の辺りがボトルネックになっていることが分かりました。&lt;/p&gt;

&lt;h2 id=&#34;対応:40eebbc67ccce246446fd64a1b7ebc69&#34;&gt;対応&lt;/h2&gt;

&lt;p&gt;ansible.cfgでrecord_host_keysをFalseに設定すると、&lt;a href=&#34;https://github.com/ansible/ansible/blob/4a8e0688555e7dcccb84732962d00af0b8274431/lib/ansible/runner/connection_plugins/paramiko_ssh.py#L325&#34;&gt;このif&lt;/a&gt; の分岐でConnection#closeのhostkeyの処理をまとめて飛ばせるので、かなり高速化します。&lt;/p&gt;

&lt;p&gt;もしくはこの処理はparamiko特有の処理なので、sshを接続に用いれば影響はなくなります。&lt;/p&gt;

&lt;p&gt;諸々検証が済んだ後に気づいたのですが、実はそのあたりのことは &lt;a href=&#34;http://docs.ansible.com/intro_configuration.html#record-host-keys&#34;&gt;公式ドキュメント&lt;/a&gt; に書いてあります。&lt;/p&gt;

&lt;h2 id=&#34;速度:40eebbc67ccce246446fd64a1b7ebc69&#34;&gt;速度&lt;/h2&gt;

&lt;p&gt;50ホストを対象に、copyを中心に10タスクずつのplaybookの実行時間&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;real 8m6.174s
user 8m59.837s
sys 0m14.554s
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;real 1m23.947s
user 1m54.972s
sys 0m10.593s
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;openssh-6-6p1:40eebbc67ccce246446fd64a1b7ebc69&#34;&gt;OpenSSH 6.6p1&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;real 0m46.788s
user 0m43.508s
sys 0m15.472s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;opensshが一番速いですが、独自ビルドして利用するのはちょっとという場合は、record_host_keysをFalseにしておくだけでも十分な効果が見込めますね。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>fluent-tailというツールを書いた</title>
      <link>http://chopl.in/post/2014/03/06/introduction_of_fluent_tail/</link>
      <pubDate>Thu, 06 Mar 2014 00:00:00 UTC</pubDate>
      
      <guid>http://chopl.in/post/2014/03/06/introduction_of_fluent_tail/</guid>
      <description>

&lt;h2 id=&#34;tl-dr:da110087423a72380e5b2b6f806ae0ab&#34;&gt;tl;dr&lt;/h2&gt;

&lt;p&gt;fluentdを使っていると、そのストリームにどういうデータが流れているか確認したいことが頻繁にあって、そういう時に一々copy → stdoutなconfigを追加してreloadするのが面倒なので、専用のツールを書きました。&lt;/p&gt;

&lt;p&gt;これ → &lt;a href=&#34;https://github.com/choplin/fluent-tail&#34;&gt;choplin/fluent-tail&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;インストール:da110087423a72380e5b2b6f806ae0ab&#34;&gt;インストール&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ fluent-gem install fluent-tail
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;事前準備:da110087423a72380e5b2b6f806ae0ab&#34;&gt;事前準備&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;in_debug_agent&lt;/code&gt; が提供しているdrubyの入り口を使うので有効にしておいて下さい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
type debug_agent
&amp;lt;/source&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;使い方:da110087423a72380e5b2b6f806ae0ab&#34;&gt;使い方&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;match&amp;gt;&lt;/code&gt; と同様の形式でパターンを指定すると、そのパターンにマッチしたイベントが標準出力に出ます。&lt;/p&gt;

&lt;p&gt;fluentdを起動して&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ fluentd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;fluent-tailを実行する&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ fluent-tail &amp;quot;foo.**&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;そこにイベントを流すと、指定したパターンにマッチしたイベントだけ表示されます&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ &#39;{&amp;quot;a&amp;quot;:&amp;quot;b&amp;quot;}&#39; | fluent-cat foo
$ &#39;{&amp;quot;a&amp;quot;:&amp;quot;b&amp;quot;}&#39; | fluent-cat foo.bar
$ &#39;{&amp;quot;a&amp;quot;:&amp;quot;b&amp;quot;}&#39; | fluent-cat hoge
$ &#39;{&amp;quot;a&amp;quot;:&amp;quot;b&amp;quot;}&#39; | fluent-cat foo.bar.foo

2014-03-06 14:22:21 +0900 foo: {&amp;quot;a&amp;quot;:&amp;quot;b&amp;quot;}
2014-03-06 14:22:23 +0900 foo.bar: {&amp;quot;a&amp;quot;:&amp;quot;b&amp;quot;}
2014-03-06 14:22:27 +0900 foo.bar.foo: {&amp;quot;a&amp;quot;:&amp;quot;b&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以上。簡単ですね。&lt;/p&gt;

&lt;h2 id=&#34;注意点:da110087423a72380e5b2b6f806ae0ab&#34;&gt;注意点&lt;/h2&gt;

&lt;p&gt;内部的には、 druby で実行中のfluentdプロセスに接続して、 &lt;code&gt;instance_eval&lt;/code&gt; で &lt;code&gt;Engine#emit_stream&lt;/code&gt; というfluentのルーティングの根幹の部分を、実行時に書き換えるということをしているので、安全性については何ともです。&lt;/p&gt;

&lt;p&gt;私は今のところ問題なく使えてますが、↑を認識した上で注意して使って下さい。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>chefの辛み</title>
      <link>http://chopl.in/post/2014/01/19/chef_makes_me_tired/</link>
      <pubDate>Sun, 19 Jan 2014 00:00:00 UTC</pubDate>
      
      <guid>http://chopl.in/post/2014/01/19/chef_makes_me_tired/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;※注: chefがクソだというつもりは毛頭なくて、我々のツールの選定や運用の方法が間違っている気がするという話です&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;現在、社内の構成管理ツールにはchefを使っています。使い始めて一年ちょっと経つんですが、色々と辛いと感じる部分が出てきたのでまとめておきます。&lt;/p&gt;

&lt;h2 id=&#34;前提:86bd0d8319e05a29ddc7faddfc4255cb&#34;&gt;前提&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;ノードの数は150程度、種類は15程度&lt;/li&gt;
&lt;li&gt;cookbookは40程度&lt;/li&gt;
&lt;li&gt;chef serverを使用&lt;/li&gt;
&lt;li&gt;chef-clientの実行は手動で行っている。意図しない変更が本番に入るのを防ぐため。&lt;/li&gt;
&lt;li&gt;一部まだの部分はあるけど大体の構成の管理はchefに移行出来ている&lt;/li&gt;
&lt;li&gt;まだの部分もchef管理へ移行することが推奨されている&lt;/li&gt;
&lt;li&gt;運用で必要になることが多いので、サーバーでの直接の変更は禁止されていない&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;辛み:86bd0d8319e05a29ddc7faddfc4255cb&#34;&gt;辛み&lt;/h2&gt;

&lt;h3 id=&#34;chef-clientが遅い:86bd0d8319e05a29ddc7faddfc4255cb&#34;&gt;chef-clientが遅い&lt;/h3&gt;

&lt;p&gt;今適当なサーバーで測ったら、適用するものがない状態で20秒弱かかりました。実行前にwhy runで差分を確認するようにしているので、この時間分は必ず待たされることになります。&lt;/p&gt;

&lt;p&gt;時間がかかっているcookbooksのcompile、ついでyumなどの一部遅いresourceな感じです。後者はしょうがない気もしますが。&lt;/p&gt;

&lt;h3 id=&#34;最終的にどういう状態になるか把握しにくい:86bd0d8319e05a29ddc7faddfc4255cb&#34;&gt;最終的にどういう状態になるか把握しにくい&lt;/h3&gt;

&lt;p&gt;chefは大変柔軟に設定ができるんですが、その半面、結局サーバーがどういう状態になる設定なのか、chefリポジトリの内容を眺めているだけでは分かりにくくなっているように感じます。&lt;/p&gt;

&lt;p&gt;分かりにくくなる要因としては、以下のようなところでしょうか。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;run_listが複数箇所(node, role)で設定できる&lt;/li&gt;
&lt;li&gt;run_listに設定できる要素が複数(role, recipe)ある&lt;/li&gt;
&lt;li&gt;recipeを集約する方法が複数(run_list, include_recipe)ある&lt;/li&gt;
&lt;li&gt;attributeの設定箇所が複数ある&lt;/li&gt;
&lt;li&gt;内部DSLなのでrubyで何でもできてしまう&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;chefのリポジトリを見通しのいい状態に保つためには利用方法に合わせた運用ルールをチームで共有する必要があるのではないかと思うのですが、そもそもコードに残らない運用を減らすために構成管理ツールを導入したので、そういったルールは最小限に留めたいです。berkshelfなどの運用方法をある程度強制するツールを導入すれば楽になるかも。&lt;/p&gt;

&lt;h3 id=&#34;node-roleの内容がweb-uiから設定できる:86bd0d8319e05a29ddc7faddfc4255cb&#34;&gt;node, roleの内容がweb UIから設定できる&lt;/h3&gt;

&lt;p&gt;言いがかりなんですが、node、roleはweb UIから設定できるので、chefリポジトリにない設定を入れてしまうことが可能です。そうなってしまうと、サーバーの状態の追跡が、chefリポジトリのみからでは分かりにくいだけでなく不可能になってしまう。運用ルールで禁止すればいいんですが同上。&lt;/p&gt;

&lt;h3 id=&#34;その他:86bd0d8319e05a29ddc7faddfc4255cb&#34;&gt;その他&lt;/h3&gt;

&lt;p&gt;他、細かいところだと&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;run_listの一部の適用が若干やりにくい&lt;/li&gt;
&lt;li&gt;変更したrecipeがどのnodeに適用されるかが分かりにくい (knifeのクエリでできるかも。利用してないのですが。）&lt;/li&gt;
&lt;li&gt;chefリポジトリの状態がgitとchef serverの二重管理になっているのでまとめたい。hookかけてuploadしてもいいかもしれない。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;まとめ:86bd0d8319e05a29ddc7faddfc4255cb&#34;&gt;まとめ&lt;/h2&gt;

&lt;p&gt;この記事を書いていて思いついたのはこんなところでしょうか。思いつくままに書いたので余りまとまったないですが。&lt;/p&gt;

&lt;p&gt;冒頭に書いたようにdisるつもりは全くなくて、むしろそのやり方間違っているからこうしろというのを教えて欲しいです。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>fluentdのoutputプラグインでブロックするものはBufferedOutputを使うべき</title>
      <link>http://chopl.in/post/2014/01/19/user_bufferedoutput_for_blocking_plugin_instead_of_output/</link>
      <pubDate>Sun, 19 Jan 2014 00:00:00 UTC</pubDate>
      
      <guid>http://chopl.in/post/2014/01/19/user_bufferedoutput_for_blocking_plugin_instead_of_output/</guid>
      <description>

&lt;h2 id=&#34;tl-dr:4b3389530300ccc83bf2f7bb68d99c5f&#34;&gt;tl;dr&lt;/h2&gt;

&lt;p&gt;タイトルのまま&lt;/p&gt;

&lt;h2 id=&#34;前置き:4b3389530300ccc83bf2f7bb68d99c5f&#34;&gt;前置き&lt;/h2&gt;

&lt;p&gt;fluentdクラスタのあるノードにだけ、そのノードに送信しているout_forwardがdetachされ続けるという症状が出ました。&lt;/p&gt;

&lt;p&gt;調査したところ、外部への通知用に追加したhipchatプラグインを追加したところで症状が発生するようです。&lt;/p&gt;

&lt;h2 id=&#34;原因:4b3389530300ccc83bf2f7bb68d99c5f&#34;&gt;原因&lt;/h2&gt;

&lt;p&gt;BufferedOutputプラグインでの write メソッドでのスタックトレースはこんな風になります。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/home/choplin/git/fluentd/lib/fluent/buffer.rb:296:in `write_chunk&#39;
/home/choplin/git/fluentd/lib/fluent/buffer.rb:276:in `pop&#39;
/home/choplin/git/fluentd/lib/fluent/output.rb:309:in `try_flush&#39;
/home/choplin/git/fluentd/lib/fluent/output.rb:131:in `run&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一方、Outputプラグインでの emit メソッドでのスタックトレースはこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/home/choplin/git/fluentd/lib/fluent/match.rb:36:in `emit&#39;
/home/choplin/git/fluentd/lib/fluent/engine.rb:151:in `emit_stream&#39;
/home/choplin/git/fluentd/lib/fluent/plugin/in_forward.rb:133:in `on_message&#39;
/home/choplin/git/fluentd/lib/fluent/plugin/in_forward.rb:185:in `feed_each&#39;
/home/choplin/git/fluentd/lib/fluent/plugin/in_forward.rb:185:in `on_read_msgpack&#39;
/home/choplin/git/fluentd/lib/fluent/plugin/in_forward.rb:173:in `call&#39;
/home/choplin/git/fluentd/lib/fluent/plugin/in_forward.rb:173:in `on_read&#39;
/home/choplin/.rbenv/versions/1.9.3-p194/lib/ruby/gems/1.9.1/gems/cool.io-1.1.1/lib/cool.io/io.rb:108:in `on_readable&#39;
/home/choplin/.rbenv/versions/1.9.3-p194/lib/ruby/gems/1.9.1/gems/cool.io-1.1.1/lib/cool.io/io.rb:170:in `on_readable&#39;
/home/choplin/.rbenv/versions/1.9.3-p194/lib/ruby/gems/1.9.1/gems/cool.io-1.1.1/lib/cool.io/loop.rb:96:in `run_once&#39;
/home/choplin/.rbenv/versions/1.9.3-p194/lib/ruby/gems/1.9.1/gems/cool.io-1.1.1/lib/cool.io/loop.rb:96:in `run&#39;
/home/choplin/git/fluentd/lib/fluent/plugin/in_forward.rb:81:in `run&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ここで注目すべきは &lt;code&gt;in_forward.rb:133:in on_message&lt;/code&gt; で、これは &lt;code&gt;Engine.emit_stream(tag, es)&lt;/code&gt; の呼び出しです。つまりOutputプラグインの &lt;code&gt;emit&lt;/code&gt; はInputプラグインの &lt;code&gt;Engine.emit&lt;/code&gt; から(複数のメソッド呼び出しを経て)直接呼び出されています。&lt;/p&gt;

&lt;p&gt;その為、Outputプラグイン &lt;code&gt;emit&lt;/code&gt; でブロックする処理が入ると、その間in_forwardのイベントループがブロックされることになります。&lt;/p&gt;

&lt;p&gt;in_forwardのイベントループはout_forwardの死活監視のheartbeat packetへの返信にも用いられているため、イベントループがブロックされることでheartbeatを返せなくなり、detachされるというわけです。&lt;/p&gt;

&lt;p&gt;実際に私の環境でhipchatプラグイン emit で行っている処理の時間を測ったところ、平均で0.7sec、たまに3secを超えてタイムアウトする、という状況でした。これ位の値だとOutputではダメで、BufferedOutputにすべきなのでしょう。&lt;/p&gt;

&lt;h2 id=&#34;解決方法:4b3389530300ccc83bf2f7bb68d99c5f&#34;&gt;解決方法&lt;/h2&gt;

&lt;p&gt;BuffereOutputに変える。Outputプラグインのまま回避するなら、ブロックしない処理に変えるか、out_forwardのheartbeatまわりのパラメータを調整すれば何とかなるかもしれません。&lt;/p&gt;

&lt;p&gt;特に通知系のプラグインでは通知の即時性を担保するためかOutputプラグインを用いているケースが多いようですが、この問題にはまりやすいように思うので気をつけて下さい。&lt;/p&gt;

&lt;h2 id=&#34;追記:4b3389530300ccc83bf2f7bb68d99c5f&#34;&gt;追記&lt;/h2&gt;

&lt;p&gt;@kazegusuri氏の &lt;a href=&#34;https://github.com/sabottenda/fluent-plugin-bufferize&#34;&gt;fluent-plugin-bufferize&lt;/a&gt; を使うと、Outputプラグインはそのままでも、前段にbufferを挟むことができます。痒いところに手が届く素晴らしいプラグインですね。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PostgreSQLで扱える半構造化データ型3種</title>
      <link>http://chopl.in/post/2013/12/07/unstructured_data_in_postgresql/</link>
      <pubDate>Sat, 07 Dec 2013 00:00:00 UTC</pubDate>
      
      <guid>http://chopl.in/post/2013/12/07/unstructured_data_in_postgresql/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;http://qiita.com/advent-calendar/2013/postgresql&#34;&gt;PostgreSQL Advent Calendar 2013&lt;/a&gt; の7日目の記事です。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://qiita.com/choplin/items/9d5e2ff8721fb9509bf8&#34;&gt;前回&lt;/a&gt; は配列や複合型などの既存の型を組み合わせることができる型を紹介したので、今回はpostgresで非構造化データ型を3種類紹介します。&lt;/p&gt;

&lt;h2 id=&#34;半構造化データ型:d5f8351c8ae33b89ef3ec54ab8723d4a&#34;&gt;半構造化データ型&lt;/h2&gt;

&lt;p&gt;厳密に定義はないと思うのですが、本エントリでは厳密な定義を持たずに、内部に配列やハッシュなどの構造と、値を持つようなデータを指すこととします。&lt;/p&gt;

&lt;p&gt;postgresではいくつか半構造化データのフォーマットを型として扱うことができます。&lt;/p&gt;

&lt;h2 id=&#34;使いどころ:d5f8351c8ae33b89ef3ec54ab8723d4a&#34;&gt;使いどころ&lt;/h2&gt;

&lt;p&gt;RDBMSでは、あらかじめテーブル設計を行って、各テーブルにどの様な値が入るかを型や制約を用いてスキーマとして定義します。一般的にデータの寿命は長く、一旦データベースに意図しない値が入ってしまうと、後々に渡って非常に厄介な事態を引き起こします。そのため、そうした意図しないデータを、永続化される前に水際で食い止めることはDBMSの重要な役割の一つです。&lt;/p&gt;

&lt;p&gt;その一方で、アプリケーションの開発/運用を進めていく中で、入れたいデータの内容が変わり、スキーマの変更が必要になることがあります。RDBMSではスキーマの変更は大きな負荷となったり大きなロックが必要となったりするため、中々気軽にデータを変更することができません。&lt;/p&gt;

&lt;p&gt;予め入れたいデータの内容が変わることが予想される場合に、非構造化データ型を用いることで、スキーマの変更なく柔軟にデータの変更に対応することが可能になります。&lt;/p&gt;

&lt;p&gt;あるいは、単純に外部で利用されているフォーマットのデータをそのままDBの中に入れてしまいたいというケースも多いかもしれません。&lt;/p&gt;

&lt;p&gt;いずれにしても、半構造化データ型を用いてしまうと、冒頭で述べたスキーマでのデータのチェックが行いにくくなるため、基本的には通常のテーブルとして定義しつつ、柔軟性が必要になる限られた箇所にのみ半構造化データ型を用いる方がいいでしょう。&lt;/p&gt;

&lt;h3 id=&#34;1-xml型:d5f8351c8ae33b89ef3ec54ab8723d4a&#34;&gt;1. XML型&lt;/h3&gt;

&lt;p&gt;postgresでは組み込み型としてXMLを利用することができます。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.postgresql.jp/document/9.3/html/datatype-xml.html&#34;&gt;XML型&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT &#39;&amp;lt;foo&amp;gt;&amp;lt;bar&amp;gt;hoge&amp;lt;/bar&amp;gt;&amp;lt;bar&amp;gt;fuga&amp;lt;/bar&amp;gt;&amp;lt;/foo&amp;gt;&#39;::xml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;XMLを扱う組み込みの関数が多く用意されています。&lt;/p&gt;

&lt;p&gt;特に、標準化されたXMLを操作する構文のXPathを扱う関数があるため、XML内の任意の値を取り出すことが簡単にできます。XPathが複数の値を返すように場合には配列を返してくれます。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT xpath(&#39;//foo/bar/text()/&#39;, &amp;lt;foo&amp;gt;&amp;lt;bar&amp;gt;hoge&amp;lt;/bar&amp;gt;&amp;lt;bar&amp;gt;fuga&amp;lt;/bar&amp;gt;&amp;lt;/foo&amp;gt;&#39;::xml);

xpath
-------------
{hoge,fuga}
(1 row)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;インデックスを張りたい場合も、上記のxpath関数に、関数の結果にインデックスを張れる関数インデックス、配列などのインデックスに用いるginインデックスを組み合わせることで、XMLないの任意の箇所にインデックスを張ることが可能です。&lt;/p&gt;

&lt;h3 id=&#34;2-hstore型:d5f8351c8ae33b89ef3ec54ab8723d4a&#34;&gt;2. hstore型&lt;/h3&gt;

&lt;p&gt;hstore型はkey-valueのペアを扱う型です。組み込みではないのですが、コアと一緒に配布されるcontribと呼ばれる拡張のセットに含まれているため、通常のインストールを行っていれば簡単に利用することができます。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.postgresql.jp/document/9.3/html/hstore.html&#34;&gt;hstore&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ sudo yum install postgresql-contrib # 公式のリポジトリを利用している場合
$ psql your_database -c &#39;CREATE EXTENSION hstore&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;もちろん任意のkeyのvalueを取り出すことができます。他にも多くの演算子/関数が用意されています。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;-- hstore型の文字列表現
SELECT &#39;a =&amp;gt; 1, b =&amp;gt; 2&#39;::hstore;

-- 値の取り出し
SELECT (&#39;a =&amp;gt; 1, b =&amp;gt; 2&#39;::hstore)-&amp;gt;&#39;a&#39;;

 ?column?
----------
 1
(1 row)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;インデックスはXML型と同じくginインデックスを用います。&lt;/p&gt;

&lt;p&gt;hstoreは比較的古くからあるモジュールなのですが、最近でも活発に開発が進められているため、今後さらにパフォーマンスの向上などが望めると思います。&lt;/p&gt;

&lt;h3 id=&#34;3-json型:d5f8351c8ae33b89ef3ec54ab8723d4a&#34;&gt;3. JSON型&lt;/h3&gt;

&lt;p&gt;9.2からJSON型が追加されました。9.2では主にバリデーションのみだったのですが、現在の最新バージョンである9.3で大幅にAPIが追加され、SQLからJSON内部の値を取り出せるようになりました。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.postgresql.jp/document/9.3/html/datatype-json.html&#34;&gt;JSONデータ型&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.postgresql.jp/document/9.3/html/functions-json.html&#34;&gt;JSON関数と演算子&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;-- JSON型の文字列表現
SELECT &#39;{&amp;quot;a&amp;quot;:1, &amp;quot;b&amp;quot;:[1,2,3]}&#39;::json;

-- JSON内の値の取り出し
SELECT (&#39;{&amp;quot;a&amp;quot;:1, &amp;quot;b&amp;quot;:[1,2,3]}&#39;::json)-&amp;gt;&#39;b&#39;-&amp;gt;1;

?column?
----------
2
(1 row)
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>SQL感覚でHiveQLを書くと痛い目にあう例</title>
      <link>http://chopl.in/post/2013/12/04/bad_hive_queries/</link>
      <pubDate>Wed, 04 Dec 2013 00:00:00 UTC</pubDate>
      
      <guid>http://chopl.in/post/2013/12/04/bad_hive_queries/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;http://qiita.com/advent-calendar/2013/hadoop&#34;&gt;Hadoop Advent Calendar 2013&lt;/a&gt; 4日目の記事です&lt;/p&gt;

&lt;h2 id=&#34;tl-dr:39424a15261f01941b0f172928e13b39&#34;&gt;tl;dr&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;explainとjob historyを読め&lt;/li&gt;
&lt;li&gt;1 reducerは悪&lt;/li&gt;
&lt;li&gt;data skewは悪&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;前書き:39424a15261f01941b0f172928e13b39&#34;&gt;前書き&lt;/h2&gt;

&lt;p&gt;みんな大好きSQLでHadoop上での処理を実行できるHiveにはみなさん普段からお世話になっていることでしょう。ちょっと調べ物でググる度に目に入る愛らいしいマスコットが、荒んだ心に清涼な風をはこんでくれます。&lt;/p&gt;

&lt;p&gt;ですがHiveのクエリ言語はSQLではなくHiveQLですし、実行エンジンもRDBのそれとは全く異なるMapReduceです。SQLのつもりでHiveQLを書いていると地雷を踏んでしまうことがまれによくあります。本エントリでは陥りがちなHiveQLの落とし穴を2つ紹介します。&lt;/p&gt;

&lt;h2 id=&#34;例1:39424a15261f01941b0f172928e13b39&#34;&gt;例1&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT count(DISTINCT user_id) FROM access_log
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;SQLに慣れた方であれば、集約関数の中に DISTINCT や ORDER BY を入れて用いることは多いと思います。Hiveでは全ての集約関数で利用できるわけではないのですが、この例のように count 内での DISTINCT は利用することができます。&lt;/p&gt;

&lt;p&gt;例のHiveQLではアクセスログからユニークユーザー数を計算しています。一つのクエリで完結していて美しいですね。一体どこが問題なのでしょうか？&lt;/p&gt;

&lt;p&gt;データによるところが大きいですが、以下のようにクエリを書くと速くなる場合があります。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT
    count(*)
FROM (
    SELECT
        DISTINCT
        user_id
    FROM
        access_log
) t
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;せっかく &lt;code&gt;count(DISTINCT )&lt;/code&gt; で綺麗に一つにまとめられていたところをわざわざサブクエリに分割しています。なぜこちらの方が速くなるのでしょうか？&lt;/p&gt;

&lt;p&gt;一つ目のクエリでEXPLAINを実行すると以下の様なプランになります。&lt;/p&gt;

&lt;p&gt;ここで重要な事は、全体として一つのMapReduceになっている、ということです。一つのMapReduceで重複を除きつつカウントを行うなら、Reducerは一つで処理を実行する必要があります。そのためReducerで分散処理ができず、遅くなってしまうことがある、というわけです。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -&amp;gt; Map Operator Tree:
        access_log
          TableScan
            alias: access_log
            Select Operator
              expressions:
                    expr: user_id
                    type: string
              outputColumnNames: user_id
              Group By Operator
                aggregations:
                      expr: count(DISTINCT user_id)
                bucketGroup: false
                keys:
                      expr: user_id
                      type: string
                mode: hash
                outputColumnNames: _col0, _col1
                Reduce Output Operator
                  key expressions:
                        expr: _col0
                        type: string
                  sort order: +
                  tag: -1
                  value expressions:
                        expr: _col1
                        type: bigint
      Reduce Operator Tree:
        Group By Operator
          aggregations:
                expr: count(DISTINCT KEY._col0:0._col0)
          bucketGroup: false
          mode: mergepartial
                    outputColumnNames: _col0
      Select Operator
        expressions:
              expr: _col0
              type: bigint
        outputColumnNames: _col0
        File Output Operator
          compressed: true
          GlobalTableId: 0
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat

Stage: Stage-0
Fetch Operator
  limit: -1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一方、二つ目のクエリは、サブクエリを用いているためMapReduceの数は増えていますが、user_idをpartition keyとしてデータが分割されるため、Reducerでも効率よく分散処理を行うことができます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -&amp;gt; Map Operator Tree:
        t:access_log
          TableScan
            alias: access_log
            Select Operator
              expressions:
                    expr: user_id
                    type: string
              outputColumnNames: user_id
              Group By Operator
                bucketGroup: false
                keys:
                      expr: user_id
                      type: string
                mode: hash
                outputColumnNames: _col0
                Reduce Output Operator
                  key expressions:
                        expr: _col0
                        type: string
                  sort order: +
                  Map-reduce partition columns:
                        expr: _col0
                        type: string
                  tag: -1
      Reduce Operator Tree:
        Group By Operator
          bucketGroup: false
          keys:
                expr: KEY._col0
                type: string
          mode: mergepartial
          outputColumnNames: _col0
          Select Operator
              Select Operator
                Group By Operator
                  aggregations:
                        expr: count()
                  bucketGroup: false
                  mode: hash
                  outputColumnNames: _col0
                  File Output Operator
                    compressed: true
                    GlobalTableId: 0
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

Stage: Stage-2
  Map Reduce
    Alias -&amp;gt; Map Operator Tree:
      hdfs://cdh4cluster/tmp/hive-okuno/hive_2013-12-04_13-33-10_514_1739731017764214960/-mr-10002
          Reduce Output Operator
            sort order:
            tag: -1
            value expressions:
                  expr: _col0
                  type: bigint
    Reduce Operator Tree:
      Group By Operator
        aggregations:
              expr: count(VALUE._col0)
        bucketGroup: false
        mode: mergepartial
        outputColumnNames: _col0
        Select Operator
          expressions:
                expr: _col0
                type: bigint
          outputColumnNames: _col0
          File Output Operator
            compressed: true
            GlobalTableId: 0
            table:
                input format: org.apache.hadoop.mapred.TextInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat

Stage: Stage-0
  Fetch Operator
    limit: -1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この二つの例のように、効率よくReducerを利用できているかどうか、というのは正直なところEXPLAINを見ているだけでは分かりません（熟練すれば分かるかもしれませんが）。そういう場合でも、実際にクエリを実行してみればReducerで詰まっている様子が一目で分かると思います。&lt;/p&gt;

&lt;h3 id=&#34;例2:39424a15261f01941b0f172928e13b39&#34;&gt;例2&lt;/h3&gt;

&lt;p&gt;例2のクエリはこちら。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT
    sales.product_id,
    sum(product.price * sales.num)
FROM
    sales
INNER JOIN
    product ON sales.product_id = product.product_id
GROUP BY
    sales.product_id
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;販売履歴に商品マスタをJOINして、商品毎の売上をだしている、と想定して下さい。&lt;/p&gt;

&lt;p&gt;このクエリは以下のようにすると速くなる可能性があります。（もちろんデータによります）&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT
    sales.product_id,
    product.price * total_num
FROM (
    SELECT
        product_id,
        sum(num) AS total_num
    FROM
        sales
    GROUP BY
        product_id
) sales
INNER JOIN
    product ON sales.product_id = product.product_id
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このクエリもSQLに慣れた人なら避けて最初の例のように書くのではないでしょうか。&lt;/p&gt;

&lt;p&gt;後者の例が速くなるポイントはデータの偏り(data skew)です。&lt;/p&gt;

&lt;p&gt;一つ目のクエリでは、salesおよびproductのデータがproduct_idでpartitionされてReducerに配られます。その時、sales内に飛び抜けて売れた商品があると、あるReducerにだけデータが大量に集まってきてしまいます。そうした大量のデータに対するJOINは非常に遅い処理になってしまいます。その結果、そのReducerだけ処理時間が長くなってしまい、結局Job全体としても遅くなります。&lt;/p&gt;

&lt;p&gt;一方、二つ目のクエリではMapReduceの数は増えてしまいますが、一段目のMapReduceではMap側集約を利用でき効率よく集約を行うことができます。二段目のMapReduceでは一段目でsalesがproduct_idで集約されて各product_idについて一行しか存在しないため、productとのJOINも非常に軽い処理で済むようになっています。&lt;/p&gt;

&lt;p&gt;但し、product側が十分に小さくmap-site joinが利用できる場合は話が全く別です。その場合は、まず間違いなく一つ目のクエリの方が速くなるでしょう。&lt;/p&gt;

&lt;h2 id=&#34;まとめ:39424a15261f01941b0f172928e13b39&#34;&gt;まとめ&lt;/h2&gt;

&lt;p&gt;Hiveは大変便利なのですが、上記の例のようにデータの量や偏りによって効率のいいクエリが全く異なるケースがあって厄介です（RDBでも同じですが）。クエリを選択する際にはSQLの常識は通じないことが多いので、Hiveを利用する際にはその事を意識しておくべきでしょう。めんどうでもEXPLAINでプランを見つつ、実際に実行してみて効率の悪いMapReduceになっていないか常にチェックしていくしかないと思います。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PostgreSQLでテーブル名カラム名を取得する方法</title>
      <link>http://chopl.in/post/2013/11/07/how_to_retrieve_tables_and_columns_with_postgres/</link>
      <pubDate>Thu, 07 Nov 2013 00:00:00 UTC</pubDate>
      
      <guid>http://chopl.in/post/2013/11/07/how_to_retrieve_tables_and_columns_with_postgres/</guid>
      <description>

&lt;h2 id=&#34;motivation:781493656d1c58c584dc4bcec54d5d78&#34;&gt;Motivation&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://exiz.org/database/postgres/2013110716431/&#34;&gt;PostgreSQLのテーブルのカラム情報などを取得する | ExiZ.org&lt;/a&gt; を読んで気になったのでコメントしておきます&lt;/p&gt;

&lt;h2 id=&#34;結論:781493656d1c58c584dc4bcec54d5d78&#34;&gt;結論&lt;/h2&gt;

&lt;p&gt;psqlで\d使おう。&lt;/p&gt;

&lt;h2 id=&#34;元エントリのクエリ:781493656d1c58c584dc4bcec54d5d78&#34;&gt;元エントリのクエリ&lt;/h2&gt;

&lt;p&gt;基本的には問題ないのですが&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT
    relname AS table_name
FROM
    pg_stat_user_tables
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;pg_stat&lt;/code&gt; というテーブルは標準統計情報ビューと呼ばれます。ざっくりと説明すると、PostgreSQLは自身がどう使われているかについての情報を収集する機能があり、統計情報ビューを通してその情報を見ることができます。&lt;/p&gt;

&lt;p&gt;このクエリの &lt;code&gt;pg_stat_user_tables&lt;/code&gt; というビューではユーザーが定義したテーブルへのアクセスの状況を見ることができます。例えば、テーブルの大体の行数を調べたい時には、 &lt;code&gt;select count(*)&lt;/code&gt; で計算しなおすのではなくて、このビューの &lt;code&gt;n_live_tup&lt;/code&gt; を見ると分かります。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.postgresql.jp/document/current/html/monitoring-stats.html&#34;&gt;統計情報コレクタ&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT
    *
FROM
    information_schema.columns
WHERE
    table_name = &#39;テーブル名&#39;
ORDER BY
    ordinal_position;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;information_schema&lt;/code&gt; とはデータベース内の様々メタデータを取得するために標準SQLで定められているビューの集合です。PostgreSQLでは直接メタデータを格納しているテーブルへのビューとして定義されています。&lt;/p&gt;

&lt;p&gt;SQLの移植性を高めるという点ではinformation_schemaを用いる方が正解かも知れませんが、直接PostgreSQLでのメタデータのテーブルへ問い合わせる方が、少し&amp;rdquo;らしい&amp;rdquo;かも。&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:781493656d1c58c584dc4bcec54d5d78:1&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:781493656d1c58c584dc4bcec54d5d78:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.postgresql.jp/document/current/html/information-schema.html&#34;&gt;情報スキーマ&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;システムカタログ:781493656d1c58c584dc4bcec54d5d78&#34;&gt;システムカタログ&lt;/h2&gt;

&lt;p&gt;システムカタログとはPostgreSQL内のメタデータを管理するテーブルです。 &lt;code&gt;CREATE TABLE&lt;/code&gt; や &lt;code&gt;ALTER INDEX&lt;/code&gt; などのDDLを実行すると、このテーブルの値が書き換わります。&lt;/p&gt;

&lt;p&gt;DB内部での処理も実際にこのテーブルの値を通して各種のメタデータへアクセスするようになっています。 &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:781493656d1c58c584dc4bcec54d5d78:2&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:781493656d1c58c584dc4bcec54d5d78:2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; 即ち、内部での処理に利用する値がテーブルとして公開されており、ユーザーからSQLを通して取得できるようになっている、というわけです。 DBで管理している種々のメタデータがそのままユーザーに公開されているというのはPostgreSQLの一つの特徴といえるかもしれません。&lt;/p&gt;

&lt;p&gt;管理する対象に応じて色々なテーブルがあるので、こちらを参照して下さい。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.postgresql.jp/document/current/html/catalogs.html&#34;&gt;システムカタログ&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;これらのシステムカタログを経由してテーブルや列の一覧を取得することができます。&lt;/p&gt;

&lt;h2 id=&#34;テーブルの一覧を取得:781493656d1c58c584dc4bcec54d5d78&#34;&gt;テーブルの一覧を取得&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;pg_class&lt;/code&gt; を参照します。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT
    *
FROM
    pg_class
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;そのままだとインデックスやシステムテーブルまで入ってきてしまうので、 &lt;code&gt;relnamespace&lt;/code&gt; でスキーマを指定したり、 &lt;code&gt;relkind&lt;/code&gt; で通常テーブルだけを指定したりなどで絞りこむといいです。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.postgresql.jp/document/current/html/catalog-pg-class.html&#34;&gt;pg_class&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;列の一覧を取得:781493656d1c58c584dc4bcec54d5d78&#34;&gt;列の一覧を取得&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;pg_attribute&lt;/code&gt; を参照します。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT
    *
FROM
    pg_attribute
WHERE
    attrelid = &#39;your_table_name&#39;::regclass;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;attrelid&lt;/code&gt; という列はその列がどのテーブルに属しているかを持っています。型はOIDというPostgreSQL内部で行を一意に指定するための型です。 &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:781493656d1c58c584dc4bcec54d5d78:3&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:781493656d1c58c584dc4bcec54d5d78:3&#34;&gt;3&lt;/a&gt;&lt;/sup&gt; OID自体は数値でユーザーが指定しにくいため、pg_classなど幾つかのテーブルの行については、分かりやすいtextから直接OIDへキャストできる方法が提供されています。&lt;/p&gt;

&lt;p&gt;こちらもそのままだとシステム列や既に削除された列が含まれてしまいます。 &lt;code&gt;attnum &amp;gt; 0&lt;/code&gt; でシステム列を除いたり、 &lt;code&gt;NOT attisdropped&lt;/code&gt; で削除された列を除いたりすることが必要でしょう。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.postgresql.jp/document/current/html/catalog-pg-attribute.html&#34;&gt;pg_attribute&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;psql:781493656d1c58c584dc4bcec54d5d78&#34;&gt;psql&lt;/h2&gt;

&lt;p&gt;上記の方法はSQLを通してテーブルや列の一覧を取得する方法です。取得したテーブル名や列名を利用して何か処理するといったメタなSQLを書く必要があれば、こうした方法を取る必要がありますが、実際には一覧を見れれば十分なケースが殆どでしょう。&lt;/p&gt;

&lt;p&gt;クライアントとしてpsqlを利用していれば簡単に確認することが可能です。通常はこちらを利用するべきでしょう。&lt;/p&gt;

&lt;dl&gt;
    &lt;dt&gt;\d&lt;/dt&gt;
    &lt;dd&gt;テーブル一覧&lt;/dd&gt;
    &lt;dt&gt;\d table_name&lt;/dt&gt;
    &lt;dd&gt;指定したテーブルの列一覧&lt;/dd&gt;
&lt;/dl&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:781493656d1c58c584dc4bcec54d5d78:1&#34;&gt;information_schema経由だとpostgres特有の情報を取得できないという事情もあります
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:781493656d1c58c584dc4bcec54d5d78:1&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:781493656d1c58c584dc4bcec54d5d78:2&#34;&gt;本当はSysCache経由
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:781493656d1c58c584dc4bcec54d5d78:2&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:781493656d1c58c584dc4bcec54d5d78:3&#34;&gt;実際には周回するので一意性は保証されていないのですが
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:781493656d1c58c584dc4bcec54d5d78:3&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>ブログ書くならreStructuredText</title>
      <link>http://chopl.in/post/2013/09/10/blogging_with_re_structured_text/</link>
      <pubDate>Tue, 10 Sep 2013 00:00:00 UTC</pubDate>
      
      <guid>http://chopl.in/post/2013/09/10/blogging_with_re_structured_text/</guid>
      <description>&lt;p&gt;This post is written with &lt;a href=&#34;http://docutils.sourceforge.net/rst.html&#34;&gt;reStructuredText&lt;/a&gt; and published using &lt;a href=&#34;http://tinkerer.me/&#34;&gt;Tinkerer&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ref: &lt;a href=&#34;http://tande.jp/lab/2012/07/1838&#34;&gt;ブログ書くなら Pukiwiki記法 か Markdown記法 か | tande lab.&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>vimに感謝の気持ちを伝える方法</title>
      <link>http://chopl.in/post/2013/08/11/donate_money_to_uganda_for_vim/</link>
      <pubDate>Sun, 11 Aug 2013 00:00:00 UTC</pubDate>
      
      <guid>http://chopl.in/post/2013/08/11/donate_money_to_uganda_for_vim/</guid>
      <description>

&lt;p&gt;vim 7.4がリリースされたので感謝の気持ちを伝えましょう&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;:help uganda
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;追記:a62cead8d49f99ec8653dc05322c92b1&#34;&gt;追記&lt;/h2&gt;

&lt;p&gt;よく分からないという人はここのpaypalのMake A Donationをクリックするといいのでは&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://iccf-holland.org/donate.html&#34;&gt;ICCF Holland - Donation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PostgreSQLのログをfluentdで回収する設定</title>
      <link>http://chopl.in/post/2013/06/07/postgresql_csv_log_with_fluentd/</link>
      <pubDate>Fri, 07 Jun 2013 00:00:00 UTC</pubDate>
      
      <guid>http://chopl.in/post/2013/06/07/postgresql_csv_log_with_fluentd/</guid>
      <description>

&lt;p&gt;PostgreSQLのログをfluentd経由で回収するようにしたので設定を晒しておきます。ほぼ同じ設定を使いまわせるはずなので、fluentd &amp;amp; postgresの組み合わせを使っている人はどうぞ。&lt;/p&gt;

&lt;h2 id=&#34;postgresql側:972d876c4986efee56c77ebbeac32ce6&#34;&gt;PostgreSQL側&lt;/h2&gt;

&lt;h3 id=&#34;postgresql-conf:972d876c4986efee56c77ebbeac32ce6&#34;&gt;postgresql.conf&lt;/h3&gt;

&lt;p&gt;postgresのログの設定はこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# csvlogを出力
logging_collector = on
log_destination = &#39;csvlog,stderr&#39;

# 1日でローテーション
log_rotation_age = 1440

# /var/log/pgsql/postgres-%Y%m%d.(log|csv)に出力
log_directory = &#39;/var/log/pgsql/&#39;
log_filename = &#39;postgres-%Y%m%d.log&#39;

# modeを644に
log_file_mode = 0644
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;cron:972d876c4986efee56c77ebbeac32ce6&#34;&gt;cron&lt;/h3&gt;

&lt;p&gt;fluentdが一意な名前で参照できるようにcronでシンボリックリンクを張り替えます。張替えの際の諸々はfluentdが面倒を見てくれるので心配いりません。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;5 0 * * * postgres ln -sf /var/log/pgsql/postgres-$(date +&#39;\\%Y\\%m\\%d&#39;).csv /var/log/pgsql/postgres.csv
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;flunetd側:972d876c4986efee56c77ebbeac32ce6&#34;&gt;flunetd側&lt;/h2&gt;

&lt;p&gt;postgresのcsvログは1レコード内に改行が含まれている可能性があるので、 &lt;a href=&#34;https://github.com/tomohisaota/fluent-plugin-tail-multiline&#34;&gt;fluent-plugin-tail-multiline&lt;/a&gt; を利用します。&lt;/p&gt;

&lt;p&gt;fluent-plugin-tail-multilineはtailに組み込みのパーサーは利用できないので正規表現で記述する必要があります。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  type        tail_multiline
  time_key    log_time
  time_format %Y-%m-%d %H:%M:%S.%L %Z
  path        /var/log/pgsql/postgres.csv
  tag         postgresql
  pos_file    /var/log/td-agent/postgresql.log.pos

  format_firstline /^\d{4}-\d{2}-\d{2}/

  format /^(?&amp;lt;time&amp;gt;[^&amp;quot;,]*),&amp;quot;?(?&amp;lt;user_name&amp;gt;(?:[^&amp;quot;]|&amp;quot;&amp;quot;)*)&amp;quot;?,&amp;quot;?(?&amp;lt;database_name&amp;gt;(?:[^&amp;quot;]|&amp;quot;&amp;quot;)*)&amp;quot;?,(?&amp;lt;process_id&amp;gt;[^&amp;quot;,]*),&amp;quot;?(?&amp;lt;connection_from&amp;gt;(?:[^&amp;quot;]|&amp;quot;&amp;quot;)*)&amp;quot;?,(?&amp;lt;session_id&amp;gt;[^&amp;quot;,]*),(?&amp;lt;session_line_num&amp;gt;[^&amp;quot;,]*),&amp;quot;?(?&amp;lt;command_tag&amp;gt;(?:[^&amp;quot;]|&amp;quot;&amp;quot;)*)&amp;quot;?,(?&amp;lt;session_start_time&amp;gt;[^&amp;quot;,]*),(?&amp;lt;virtual_transaction_id&amp;gt;[^&amp;quot;,]*),(?&amp;lt;transaction_id&amp;gt;[^&amp;quot;,]*),(?&amp;lt;error_severity&amp;gt;[^&amp;quot;,]*),(?&amp;lt;sql_state_code&amp;gt;[^&amp;quot;,]*),&amp;quot;?(?&amp;lt;message&amp;gt;(?:[^&amp;quot;]|&amp;quot;&amp;quot;)*)&amp;quot;?,(?&amp;lt;detail&amp;gt;[^&amp;quot;,]*),&amp;quot;?(?&amp;lt;hint&amp;gt;(?:[^&amp;quot;]|&amp;quot;&amp;quot;)*)&amp;quot;?,(?&amp;lt;internal_query&amp;gt;[^&amp;quot;,]*),(?&amp;lt;internal_query_pos&amp;gt;[^&amp;quot;,]*),(?&amp;lt;context&amp;gt;[^&amp;quot;,]*),(?&amp;lt;query&amp;gt;[^&amp;quot;,]*),(?&amp;lt;query_pos&amp;gt;[^&amp;quot;,]*),(?&amp;lt;location&amp;gt;[^&amp;quot;,]*),&amp;quot;?(?&amp;lt;application_name&amp;gt;(?:[^&amp;quot;]|&amp;quot;&amp;quot;)*)&amp;quot;?$/

&amp;lt;/source&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この設定をしておけば、こんな感じのメッセージが取れます&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tag: postgres
time: 2013-06-07 06:00:30 +0000
record: {
 &amp;quot;application_name&amp;quot;: &amp;quot;psql&amp;quot;,
 &amp;quot;location&amp;quot;: &amp;quot;&amp;quot;,
 &amp;quot;query_pos&amp;quot;: &amp;quot;&amp;quot;,
 &amp;quot;query&amp;quot;: &amp;quot;&amp;quot;,
 &amp;quot;context&amp;quot;: &amp;quot;&amp;quot;,
 &amp;quot;internal_query_pos&amp;quot;: &amp;quot;&amp;quot;,
 &amp;quot;session_start_time&amp;quot;: &amp;quot;2013-06-07 06:00:13 GMT&amp;quot;,
 &amp;quot;command_tag&amp;quot;: &amp;quot;SELECT&amp;quot;,
 &amp;quot;session_line_num&amp;quot;: &amp;quot;1&amp;quot;,
 &amp;quot;session_id&amp;quot;: &amp;quot;51b176ed.4f4e&amp;quot;,
 &amp;quot;connection_from&amp;quot;: &amp;quot;[local]&amp;quot;,
 &amp;quot;process_id&amp;quot;: &amp;quot;20302&amp;quot;,
 &amp;quot;database_name&amp;quot;: &amp;quot;my_database&amp;quot;,
 &amp;quot;user_name&amp;quot;: &amp;quot;postgres&amp;quot;,
 &amp;quot;virtual_transaction_id&amp;quot;: &amp;quot;109/0&amp;quot;,
 &amp;quot;transaction_id&amp;quot;: &amp;quot;0&amp;quot;,
 &amp;quot;error_severity&amp;quot;: &amp;quot;LOG&amp;quot;,
 &amp;quot;sql_state_code&amp;quot;: &amp;quot;00000&amp;quot;,
 &amp;quot;message&amp;quot;: &amp;quot;duration: 11002.537 ms  statement: select pg_sleep(11);&amp;quot;,
 &amp;quot;detail&amp;quot;: &amp;quot;&amp;quot;,
 &amp;quot;hint&amp;quot;: &amp;quot;&amp;quot;,
 &amp;quot;internal_query&amp;quot;: &amp;quot;&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;その後:972d876c4986efee56c77ebbeac32ce6&#34;&gt;その後&lt;/h2&gt;

&lt;p&gt;この設定でログを全て集約できます。利用方法の例としては、スロークエリの検知などに使えますね。&lt;/p&gt;

&lt;p&gt;その場合は、messageのフィールドにスロークエリ周りの情報がまとめて入ってしまっているので、 &lt;a href=&#34;https://github.com/y-ken/fluent-plugin-rewrite-tag-filter&#34;&gt;fluent-plugin-rewrite-tag-filter&lt;/a&gt; でスロークエリとそれ以外でtagを振り分けた後に、 &lt;a href=&#34;https://github.com/tagomoris/fluent-plugin-parser&#34;&gt;fluent-plugin-parser&lt;/a&gt; や &lt;a href=&#34;https://github.com/tomity/fluent-plugin-map&#34;&gt;fluent-plugin-map&lt;/a&gt; などrecordを書き換えられるpluginでパースしてやればいいと思います。&lt;/p&gt;

&lt;h2 id=&#34;追記:972d876c4986efee56c77ebbeac32ce6&#34;&gt;追記&lt;/h2&gt;

&lt;p&gt;投げっぱなしも何なので、スロークエリのみを取り分けて、messageをパースして、結果を &lt;a href=&#34;http://kibana.org/&#34;&gt;Kibana&lt;/a&gt; に入れるところまでの設定を書いておきます。Kibanaに入れておけば、検索はできるわ統計は取れるわでウハウハです。これからはfluentdにKibanaの時代ですね。&lt;/p&gt;

&lt;p&gt;下記の設定だとスロークエリ以外のログは捨ててますが、一緒にKinabaに入れてもいいかもしれません。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;match postgresql&amp;gt;
  type rewrite_tag_filter

  rewriterule1 message ^duration: postgresql.slow_query
  rewriterule2 message .*         postgresql.others
&amp;lt;/match&amp;gt;

&amp;lt;match postgresql.others&amp;gt;
  type null
&amp;lt;/match&amp;gt;

&amp;lt;match postgresql.slow_query&amp;gt;
  type         parser
  add_prefix   parsed
  reserve_data yes
  key_name     message

  format /^duration: (?&amp;lt;duration&amp;gt;[0-9\.]+) ms  statement: (?&amp;lt;statement&amp;gt;.+)$/
&amp;lt;/match&amp;gt;

&amp;lt;match parsed.postgresql.slow_query&amp;gt;
  type elasticsearch
  logstash_format true
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これだけの設定をしておけば、Kibanaに全部のスロークエリが入ってきます。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../img/blog/kibana_slow_query.jpg&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;いい感じですね。ログはいざという時にパッと見れないと困るので、こうやっていつでも誰でも見れるようにしておくと捗りますね。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>fluentd自身のログにまつわるノウハウ</title>
      <link>http://chopl.in/post/2013/04/27/fluentd_internal_log/</link>
      <pubDate>Sat, 27 Apr 2013 00:00:00 UTC</pubDate>
      
      <guid>http://chopl.in/post/2013/04/27/fluentd_internal_log/</guid>
      <description>

&lt;h2 id=&#34;fluentdのログ:8a2abdda537ed6059bf55844a19ae9b7&#34;&gt;fluentdのログ&lt;/h2&gt;

&lt;p&gt;流行に敏いみなさまは既にfluentdのクラスタを組まれているかと思います &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:8a2abdda537ed6059bf55844a19ae9b7:1&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:8a2abdda537ed6059bf55844a19ae9b7:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; が、fluentd自体のログはどうしてますでしょうか？&lt;/p&gt;

&lt;p&gt;サーバーに直接入って確認している？せっかくログアグリゲーターを組んでいるのだから、fluentd自体のログもfluentdで管理しませんか。&lt;/p&gt;

&lt;p&gt;fluentdでは以下の様な match を定義しておくと、自身のログをメッセージとして流すようになっています。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;match fluent.**&amp;gt;
...
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;流れてくるメッセージはこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fluent.info: {&amp;quot;message&amp;quot;:&amp;quot;force flushing buffered events&amp;quot;}
fluent.warn: {&amp;quot;message&amp;quot;:&amp;quot;emit transaction failed&amp;quot;}
fluent.error: {&amp;quot;message&amp;quot;:&amp;quot;forward error: queue size exceeds limit&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちなみに、 &lt;code&gt;no patterns matched tag&lt;/code&gt; のwarningを不必要に出さ無いために、適切な &lt;code&gt;match&lt;/code&gt; がない場合はメッセージを流さないようになっています。気が効いていますね。&lt;/p&gt;

&lt;p&gt;また、ここでの適切な &lt;code&gt;match&lt;/code&gt; とは、 &lt;code&gt;fluentd&lt;/code&gt; というマッチするかどうかです。実際に流れるメッセージは &lt;code&gt;fluent.warn&lt;/code&gt; などの形なので一見 &lt;code&gt;&amp;lt;match fluent.*&amp;gt;&lt;/code&gt; でも大丈夫そうなのですが、これだと &lt;code&gt;fluent&lt;/code&gt; タグはマッチしないのでメッセージは流れるようになりません。気をつけて下さい。&lt;/p&gt;

&lt;p&gt;この設定を入れておくとfluentdにメッセージとして流れるようになるので、後は各種プラグインで好きに加工して下さい。&lt;/p&gt;

&lt;h2 id=&#34;設定例:8a2abdda537ed6059bf55844a19ae9b7&#34;&gt;設定例&lt;/h2&gt;

&lt;p&gt;私の設定例を紹介しておきます。&lt;/p&gt;

&lt;p&gt;全ノードの設定と、それを集約して利用するwatcherノード用の設定に分かれています。&lt;/p&gt;

&lt;h3 id=&#34;全ノード用:8a2abdda537ed6059bf55844a19ae9b7&#34;&gt;全ノード用&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;match fluent.**&amp;gt;
  type record_modifier
  tag internal.message

  host ${hostname}
  include_tag_key
  tag_key original_tag
&amp;lt;/match&amp;gt;

&amp;lt;match internal.message&amp;gt;
  type forward
  &amp;lt;server&amp;gt;
    name watcher
    host watcher.domain
    port 24224
  &amp;lt;/server&amp;gt;
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/repeatedly/fluent-plugin-record-modifier&#34;&gt;fluent-plugin-record-modifier&lt;/a&gt; を用いて、&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ログが発生したホスト名を host として&lt;/li&gt;
&lt;li&gt;元々のタグ (fluent.warnなど)を original_tag として&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;recordに追加しています。これを入れておかないと、どこのfluentdのログか全く分からなくなるので強くオススメします。&lt;/p&gt;

&lt;p&gt;その後、watcherノードに送出します。&lt;/p&gt;

&lt;h2 id=&#34;watcherノード用:8a2abdda537ed6059bf55844a19ae9b7&#34;&gt;watcherノード用&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;match internal.message&amp;gt;
  type       filter
  all        allow
  deny       message: /^detected rotation of/, message: /^following tail of/, message: /^out_forest plants new output/
  add_prefix filtered
&amp;lt;/match&amp;gt;

&amp;lt;match filtered.internal.message&amp;gt;
  type              suppress
  interval          10
  num               2
  attr_keys         host,message
  remove_tag_prefix filtered.
  add_tag_prefix    suppressed.
&amp;lt;/match&amp;gt;

&amp;lt;match suppressed.internal.message&amp;gt;
  type     irc
  host     irc.domain
  channel  notify
  message  notice: %s [%s] @%s %s
  out_keys original_tag,time,host,message
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;やっていることは&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/muddydixon/fluent-plugin-filter&#34;&gt;fluent-plugin-filter&lt;/a&gt; で不必要なログを弾く&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/fujiwara/fluent-plugin-suppress&#34;&gt;fluent-plugin-suppress&lt;/a&gt; で連続して流れてきたログをまとめる&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/choplin/fluent-plugin-irc&#34;&gt;fluent-plugin-irc&lt;/a&gt; でircに送信&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;特に凝ったことはやっていないのですが、この辺りをやっておかないとログの量が爆発して、流しても追いきれなくなります。&lt;/p&gt;

&lt;p&gt;後は、 &lt;a href=&#34;https://github.com/tagomoris/fluent-plugin-notifier&#34;&gt;fluent-plugin-notifier&lt;/a&gt; による通知も入れたいなと妄想しています。&lt;/p&gt;

&lt;p&gt;以上の設定をしておくと、ircでは次のように表示されるようになります。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;12:06 fluentd: [11:10:24] notice: fluent.error [2013/04/27 02:10:12] @serializer.domain forward error: queue size exceeds limit
12:06 fluentd: [11:10:24] notice: fluent.warn [2013/04/27 02:10:16] @serializer.domain emit transaction failed
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これで各ノードに入って直接ログをみる必要がなくなりますね&lt;/p&gt;

&lt;h2 id=&#34;自作プラグインから流す:8a2abdda537ed6059bf55844a19ae9b7&#34;&gt;自作プラグインから流す&lt;/h2&gt;

&lt;p&gt;何かしらプラグインを書いている人は多いと思いますが、プラグインからもログを流すことができます。&lt;/p&gt;

&lt;p&gt;上記の設定と組み合わせることで、プラグインからの任意のメッセージを受け取ることができて大変捗ります。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$log.warn(&amp;quot;hoge&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;例として、私のところでは &lt;code&gt;in_tail&lt;/code&gt; を継承して少し手を入れたものを使っているのですが、パースに失敗した場合にメッセージを流すことで検知しています。&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:8a2abdda537ed6059bf55844a19ae9b7:1&#34;&gt;まだの方はGWの間にお願いします
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:8a2abdda537ed6059bf55844a19ae9b7:1&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Flunetd::MultiOutputとmonitor_agentの関係</title>
      <link>http://chopl.in/post/2013/04/24/fluentd_multioutput_and_monitor_agent/</link>
      <pubDate>Wed, 24 Apr 2013 00:00:00 UTC</pubDate>
      
      <guid>http://chopl.in/post/2013/04/24/fluentd_multioutput_and_monitor_agent/</guid>
      <description>

&lt;h2 id=&#34;monitor-agent:d4bf9af7d5a03652767a6a9867f8f6cc&#34;&gt;monitor_agent&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;fluentd v0.10.33&lt;/code&gt; で &lt;a href=&#34;https://github.com/fluent/fluentd/commit/0f88bf02721034b1b6962cc3ec9b6bc53413c098#L0R4&#34;&gt;in_monitor_agent&lt;/a&gt; が追加されました。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;in_monitor_agent&lt;/code&gt; は次の様なsourceを定義しておくと&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;...
&amp;lt;source&amp;gt;
  type monitor_agent
  bind 0.0.0.0
  port 24220
&amp;lt;/source&amp;gt;
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;http経由で、各pluginの内部の状態を取得することができるようになります。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl http://localhost:24220/api/plugins
plugin_id:object:3f8747e35fa4   type:forward    output_plugin:false
plugin_id:object:3f8747e34c30   type:debug_agent        output_plugin:false
plugin_id:object:3f874864f2f8   type:monitor_agent      output_plugin:false
plugin_id:object:3f8749cf16a0   type:stdout     output_plugin:true
plugin_id:object:3f87498b79f4   type:webhdfs    output_plugin:true      buffer_queue_length:4   buffer_total_queued_size:39798319       retry_count:0
plugin_id:object:3f8747837580   type:forward    output_plugin:true      buffer_queue_length:0   buffer_total_queued_size:0      retry_count:0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;特にBufferedOutputなpluginで内部のbufferの状態を見れるのが嬉しいですね。&lt;/p&gt;

&lt;p&gt;値を監視して &lt;code&gt;queue size exceeds limit&lt;/code&gt; が出る前にアラートを上げたり、グラフ化してピーク時にどの程度余裕があるかを測るなどの使い方ができます。&lt;/p&gt;

&lt;h2 id=&#34;内部で別のpluginを立ち上げるpluginとの関係:d4bf9af7d5a03652767a6a9867f8f6cc&#34;&gt;内部で別のpluginを立ち上げるpluginとの関係&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;fluentd&lt;/code&gt; のpluginは内部で別のpluginを立ち上げるものがあります。 &lt;code&gt;copy&lt;/code&gt; などがそうですね。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;copy&lt;/code&gt; の場合は子pluginも &lt;code&gt;monitor_agent&lt;/code&gt; を通して取得することができます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  type monitor_agent
&amp;lt;/source&amp;gt;

&amp;lt;match **&amp;gt;
  type copy
  &amp;lt;store&amp;gt;
    type stdout
  &amp;lt;/store&amp;gt;
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ curl http://localhost:24220/api/plugins
plugin_id:object:3fdddd23c774 type:monitor_agent output_plugin:false
plugin_id:object:3fdddd43e158 output_plugin:true config:
plugin_id:object:3fdddd43d67c type:stdout output_plugin:true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;copy&lt;/code&gt; 内の子pluginである &lt;code&gt;stdout&lt;/code&gt; もちゃんと見れてますね。&lt;/p&gt;

&lt;p&gt;ですが、monitor_agentで見れないpluginもあります。例えば &lt;a href=&#34;https://github.com/tagomoris/fluent-plugin-config-expander&#34;&gt;config-expander&lt;/a&gt; などがそうです。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  type monitor_agent
&amp;lt;/source&amp;gt;

&amp;lt;match **&amp;gt;
  type config_expander
  &amp;lt;config&amp;gt;
    type stdout
  &amp;lt;/config&amp;gt;
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-sourceCode&#34;&gt;curl http://localhost:24220/api/plugins
plugin_id:object:3ffa68cb3f70 type:monitor_agent output_plugin:false
plugin_id:object:3ffa68d620fc type:config_expander output_plugin:true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;config-expander&lt;/code&gt; 自体の状態は見れていますが、 &lt;code&gt;stdout&lt;/code&gt; は表示されません。&lt;/p&gt;

&lt;h2 id=&#34;原因:d4bf9af7d5a03652767a6a9867f8f6cc&#34;&gt;原因&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;MonitorAgentInput.collect_children&lt;/code&gt; はv0.10.33時点では次のような実装になっています。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;  def self.collect_children(pe, array=[])
    array &amp;lt;&amp;lt; pe
    if pe.is_a?(MultiOutput) &amp;amp;&amp;amp; pe.respond_to?(:outputs)
      pe.outputs.each {|nop|
        collect_children(nop, array)
      }
    end
    array
  end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;pe&lt;/code&gt; はoutput pluginの1つを表しています。 &lt;code&gt;array&lt;/code&gt; でmonitorする対象のpluginを返却しています。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;array&lt;/code&gt; にはplugin自身と、 &lt;code&gt;MultiOutput&lt;/code&gt; であるかつ &lt;code&gt;outputs&lt;/code&gt; を呼べる場合に子pluginを呼べる場合には、 &lt;code&gt;outputs&lt;/code&gt; の中にあるpluginが追加されます。&lt;/p&gt;

&lt;h2 id=&#34;解決法:d4bf9af7d5a03652767a6a9867f8f6cc&#34;&gt;解決法&lt;/h2&gt;

&lt;p&gt;つまり、内部で別のpluginを立ち上げる場合は、 &lt;code&gt;MultiOutput&lt;/code&gt; を継承し、 &lt;code&gt;outputs&lt;/code&gt; を外部から参照できる形にしておけば、 &lt;code&gt;monitor_agent&lt;/code&gt; で子pluginの状態を見ることができるようになります。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;config-expander&lt;/code&gt; についてはパッチを書いた（pullreq/release済み）なので参考にしてください。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt;diff --git a/lib/fluent/plugin/out_config_expander.rb b/lib/fluent/plugin/out_config_expander.rbindex a5357b6..c040da0 100644
--- a/lib/fluent/plugin/out_config_expander.rb
+++ b/lib/fluent/plugin/out_config_expander.rb
@@ -1,6 +1,6 @@
 require_relative &#39;expander&#39;

-class Fluent::ConfigExpanderOutput &amp;lt; Fluent::Output
+class Fluent::ConfigExpanderOutput &amp;lt; Fluent::MultiOutput
   Fluent::Plugin.register_output(&#39;config_expander&#39;, self)

   config_param :hostname, :string, :default =&amp;gt; `hostname`.chomp
@@ -22,6 +22,8 @@ class Fluent::ConfigExpanderOutput &amp;lt; Fluent::Output
     ex
   end

+  attr_reader :outputs
+
   def configure(conf)
     super

@@ -33,6 +35,8 @@ class Fluent::ConfigExpanderOutput &amp;lt; Fluent::Output
     @plugin = Fluent::Plugin.new_output(ex[&#39;type&#39;])
     @plugin.configure(ex)

+    @outputs = [@plugin]
+
     mark_used(configs.first)
   end
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;まとめ:d4bf9af7d5a03652767a6a9867f8f6cc&#34;&gt;まとめ&lt;/h2&gt;

&lt;p&gt;他のpluginのパッチはお願いします。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
